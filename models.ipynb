{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_MNIST, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "       \n",
    "        self.fc1 = nn.Linear(576, 576)\n",
    "        self.fc2 =  nn.Linear(576, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        x = x.view(-1, 576)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = F.softmax(self.fc2(x), dim = 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONV MODEL FOR THE TARGET & SHADOW MODEL\n",
    "\n",
    "class Net_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_CIFAR, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "       \n",
    "        self.fc1 = nn.Linear(4 * 4 * 64, 1024)\n",
    "        self.fc2 =  nn.Linear(1024, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        x = x.view(-1, 4 * 4 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = F.softmax(self.fc2(x), dim = 1)\n",
    "        return out\n",
    "#FULLY CONNECTED MODEL FOR THE ATTACKER\n",
    "\n",
    "class Net_Attack(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_Attack, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(10, 256)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 1024)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x =  self.batchnorm1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x =  self.batchnorm2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x =  self.batchnorm3(x)\n",
    "        out = F.softmax(self.fc4(x), dim = 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attack_labels(dataset_type, dataset_path, BATCH_SIZE, attack_model, target_model):\n",
    "    \n",
    "    images_path = os.path.join(dataset_path,'*.jpg')\n",
    "    counter = 0\n",
    "    if dataset_type == 1:\n",
    "        transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    elif dataset_type == 2:\n",
    "        transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5), (0.5))])\n",
    "    attack_predictions = np.array([])\n",
    "    \n",
    "    \n",
    "    \n",
    "    true_predicted = pd.read_csv(os.path.join(dataset_path,'labels.txt'), delimiter = ' ', header = None, dtype = 'str')\n",
    "    \n",
    "    true_predicted = true_predicted.rename(columns = {0: 'image_names', 1 : 'Ground_Truth'})\n",
    "    true_predicted['Ground_Truth'] = true_predicted['Ground_Truth'].astype(int)\n",
    "    \n",
    "       \n",
    "    for filename in glob.glob(os.path.join(images_path)):\n",
    "        \n",
    "        \n",
    "        im=Image.open(filename)\n",
    "        im = transform(im)\n",
    "        \n",
    "        if dataset_type == 1:\n",
    "            im = torch.reshape(im, (1, 3, 32, 32))\n",
    "        elif dataset_type == 2:\n",
    "            im = torch.reshape(im, (1, 1, 28, 28))\n",
    "        \n",
    "\n",
    "        if counter % BATCH_SIZE == 0:\n",
    "            images = im\n",
    "            img_name = []\n",
    "            img_name.append(filename.split(os.sep)[-1].split('.')[-2])\n",
    "            \n",
    "        elif (counter + 1) % BATCH_SIZE  == 0:\n",
    "\n",
    "            images = torch.cat((images, im), 0)\n",
    "            img_name.append(filename.split(os.sep)[-1].split('.')[-2])\n",
    "            \n",
    "            posteriors = target_model(images)        \n",
    "            membership_inference = attack_model(posteriors)\n",
    "            _, membership_inference = torch.max(membership_inference, 1)\n",
    "            membership_inference = membership_inference.numpy()\n",
    "            attack_predictions = np.append(attack_predictions, membership_inference)\n",
    "            \n",
    "            \n",
    "            imgs_data = pd.DataFrame(img_name, columns = {'image_names'})\n",
    "            imgs_data['Predictions'] = membership_inference.tolist()\n",
    "            \n",
    "            \n",
    "            true_predicted = true_predicted.merge(imgs_data, on = 'image_names', how = 'left')\n",
    "            \n",
    "            if counter > BATCH_SIZE:\n",
    "                true_predicted = true_predicted.rename(columns = {'Predictions_x':'Predictions'})\n",
    "                true_predicted['Predictions'] = true_predicted['Predictions'].fillna(true_predicted['Predictions_y'])\n",
    "                true_predicted.drop(columns = {'Predictions_y'}, inplace = True)\n",
    "\n",
    "        else:\n",
    "            images = torch.cat((images, im), 0)\n",
    "            img_name.append(filename.split(os.sep)[-1].split('.')[-2])\n",
    "        \n",
    "\n",
    "        counter = counter + 1            \n",
    "    \n",
    "    true_predicted = true_predicted.dropna(axis = 0, how = 'any')\n",
    "    \n",
    "    \n",
    "    return true_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def membership_inference(dataset_type, dataset_path, target_model_path):\n",
    "    \n",
    "    BATCH_SIZE = 4\n",
    "    dataset_type = int(dataset_type)\n",
    "    \n",
    "    if dataset_type == 1:\n",
    "        attack_model_path = \"./attack_model_CIFAR.pt\"\n",
    "        target_model = Net_CIFAR()\n",
    "    elif dataset_type == 2: \n",
    "        attack_model_path = \"./attack_model_MNIST.pt\"\n",
    "        target_model = Net_MNIST()\n",
    "        \n",
    "    \n",
    "    \n",
    "   \n",
    "    target_model.load_state_dict(torch.load(target_model_path))\n",
    "    \n",
    "    attack_model = Net_Attack()\n",
    "    attack_model.load_state_dict(torch.load(attack_model_path))\n",
    "    \n",
    "    true_predicted = get_attack_labels(dataset_type, dataset_path, BATCH_SIZE, attack_model, target_model)\n",
    "    \n",
    "\n",
    "    print (\"Accuracy is \", (true_predicted['Ground_Truth'] == true_predicted['Predictions']).sum()/len(true_predicted['Ground_Truth']))\n",
    "    \n",
    "    return true_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.375\n"
     ]
    }
   ],
   "source": [
    "labels = membership_inference(2, 'C:\\\\study\\\\PET\\\\Project\\\\test_dataset_1', './target_model_MNIST.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
